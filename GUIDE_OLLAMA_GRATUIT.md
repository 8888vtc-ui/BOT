# ğŸ†“ GUIDE OLLAMA GRATUIT - DeepSeek Local

## ğŸ¯ OBJECTIF

Utiliser DeepSeek **100% GRATUITEMENT** avec Ollama sur un serveur local.

---

## âœ… SOLUTION : OLLAMA + DEEPSEEK

**Ollama** permet d'hÃ©berger DeepSeek localement, **100% GRATUIT**.

---

## ğŸš€ INSTALLATION RAPIDE

### Option 1 : Railway (RecommandÃ© - Gratuit) âœ…

**Railway offre un plan gratuit parfait pour Ollama.**

#### Ã‰tape 1 : CrÃ©er Compte Railway
1. Aller sur https://railway.app
2. CrÃ©er un compte (gratuit)
3. Connecter avec GitHub

#### Ã‰tape 2 : DÃ©ployer Ollama
1. Cliquer "New Project"
2. SÃ©lectionner "Deploy from GitHub repo"
3. CrÃ©er un nouveau repo avec ce `Dockerfile` :

```dockerfile
FROM ollama/ollama:latest

# TÃ©lÃ©charger DeepSeek au dÃ©marrage
RUN ollama pull deepseek-coder
```

4. Railway dÃ©ploie automatiquement
5. RÃ©cupÃ©rer l'URL publique (ex: `https://votre-projet.railway.app`)

#### Ã‰tape 3 : Configurer Netlify
Dans Netlify Functions, ajouter :
```env
OLLAMA_URL=https://votre-projet.railway.app
OLLAMA_MODEL=deepseek-coder
```

**C'est tout !** âœ… **100% GRATUIT**

---

### Option 2 : Render (Gratuit) âœ…

**Render offre aussi un plan gratuit.**

#### Ã‰tape 1 : CrÃ©er Compte Render
1. Aller sur https://render.com
2. CrÃ©er un compte (gratuit)

#### Ã‰tape 2 : DÃ©ployer Ollama
1. Cliquer "New +" â†’ "Web Service"
2. Connecter votre repo GitHub
3. Configuration :
   - **Build Command :** `docker build -t ollama .`
   - **Start Command :** `docker run -p 11434:11434 ollama`
   - **Dockerfile :**
   ```dockerfile
   FROM ollama/ollama:latest
   RUN ollama pull deepseek-coder
   ```

4. Render dÃ©ploie automatiquement
5. RÃ©cupÃ©rer l'URL publique

#### Ã‰tape 3 : Configurer Netlify
```env
OLLAMA_URL=https://votre-service.onrender.com
OLLAMA_MODEL=deepseek-coder
```

**C'est tout !** âœ… **100% GRATUIT**

---

### Option 3 : VPS (Payant mais Flexible) ğŸ’°

**Si vous avez un VPS (Hetzner, DigitalOcean, etc.) :**

```bash
# Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh

# TÃ©lÃ©charger DeepSeek
ollama pull deepseek-coder

# DÃ©marrer Ollama (accessible publiquement)
OLLAMA_HOST=0.0.0.0:11434 ollama serve
```

**CoÃ»t :** ~$5-10/mois pour VPS

---

## ğŸ”§ CONFIGURATION NETLIFY

### Variables d'Environnement

Dans Netlify Functions, configurer :

```env
# Option 1 : Ollama (GRATUIT - PrioritÃ©)
OLLAMA_URL=https://votre-ollama.railway.app
OLLAMA_MODEL=deepseek-coder

# Option 2 : DeepSeek API (Payant - Fallback)
DEEPSEEK_API_KEY=sk-...  # Seulement si Ollama non disponible
```

**Le code utilise automatiquement Ollama si disponible, sinon DeepSeek API.**

---

## ğŸ“Š COMPARAISON

| Solution | CoÃ»t | Limites | Performance |
|----------|------|---------|-------------|
| **Ollama Railway** | **GRATUIT** âœ… | Plan gratuit | Excellente |
| **Ollama Render** | **GRATUIT** âœ… | Plan gratuit | Excellente |
| **Ollama VPS** | $5-10/mois | Aucune | Excellente |
| **DeepSeek API** | $0.004/partie | Aucune | Excellente |

**Ollama sur Railway/Render = 100% GRATUIT !** ğŸ‰

---

## âœ… AVANTAGES OLLAMA

### Avantages

1. âœ… **100% GRATUIT** (pas de coÃ»ts API)
2. âœ… **Pas de limites** de requÃªtes
3. âœ… **DonnÃ©es privÃ©es** (pas d'envoi externe)
4. âœ… **ContrÃ´le total** sur le serveur
5. âœ… **Performance** (pas de latence rÃ©seau externe)

### ModÃ¨les Disponibles

- `deepseek-coder` (recommandÃ©)
- `deepseek-chat`
- `deepseek-r1` (nouveau)

---

## ğŸ§ª TESTER L'INSTALLATION

### Test Ollama Local

```bash
# VÃ©rifier que Ollama fonctionne
curl http://localhost:11434/api/tags

# Tester DeepSeek
curl http://localhost:11434/api/generate -d '{
  "model": "deepseek-coder",
  "prompt": "Bonjour",
  "stream": false
}'
```

### Test depuis Netlify

Le code teste automatiquement si Ollama est disponible et utilise le fallback si nÃ©cessaire.

---

## ğŸ“ MODIFICATIONS CODE

**DÃ©jÃ  implÃ©mentÃ© !** âœ…

Le code a Ã©tÃ© modifiÃ© pour :
1. âœ… Utiliser Ollama en prioritÃ© (gratuit)
2. âœ… Fallback vers DeepSeek API si Ollama non disponible
3. âœ… Gestion automatique des erreurs

**Aucune modification supplÃ©mentaire nÃ©cessaire !**

---

## ğŸ¯ RÃ‰SULTAT FINAL

### Avec Ollama sur Railway/Render

**CoÃ»t :** **$0** (100% GRATUIT) ğŸ‰

**Avantages :**
- âœ… Bot niveau supÃ©rieur Ã  Snowie
- âœ… DeepSeek intÃ©grÃ©
- âœ… **Aucun coÃ»t API**
- âœ… Pas de limites

---

## ğŸ“‹ CHECKLIST

- [ ] CrÃ©er compte Railway ou Render (gratuit)
- [ ] DÃ©ployer Ollama avec DeepSeek
- [ ] Configurer `OLLAMA_URL` dans Netlify
- [ ] Tester le bot
- [ ] Profiter du bot gratuit ! ğŸ‰

---

**Avec Ollama, le bot est maintenant 100% GRATUIT !** ğŸ†“ğŸ‰

